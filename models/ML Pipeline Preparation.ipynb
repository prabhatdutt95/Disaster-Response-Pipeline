{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from random import randrange\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        0      0            0             0                 0  ...   \n",
       "1        0      0            1             0                 0  ...   \n",
       "2        0      0            0             0                 0  ...   \n",
       "3        1      0            1             0                 1  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "\n",
       "[4 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "database_file = '../data/DisasterResponse.db'\n",
    "table_name = database_file.split('.')[2].split('/')[-1]\n",
    "\n",
    "engine = create_engine('sqlite:///{}'.format(database_file))\n",
    "df = pd.read_sql(table_name, engine)\n",
    "\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Weather update - a cold front from Cuba that c...\n",
      "1                  Is the Hurricane over or is it not over\n",
      "2                          Looking for someone but no name\n",
      "3        UN reports Leogane 80-90 destroyed. Only Hospi...\n",
      "4        says: west side of Haiti, rest of the country ...\n",
      "                               ...                        \n",
      "26211    The training demonstrated how to enhance micro...\n",
      "26212    A suitable candidate has been selected and OCH...\n",
      "26213    Proshika, operating in Cox's Bazar municipalit...\n",
      "26214    Some 2,000 women protesting against the conduc...\n",
      "26215    A radical shift in thinking came about as a re...\n",
      "Name: message, Length: 26216, dtype: object        related  request  offer  aid_related  medical_help  medical_products  \\\n",
      "0            1        0      0            0             0                 0   \n",
      "1            1        0      0            1             0                 0   \n",
      "2            1        0      0            0             0                 0   \n",
      "3            1        1      0            1             0                 1   \n",
      "4            1        0      0            0             0                 0   \n",
      "...        ...      ...    ...          ...           ...               ...   \n",
      "26211        0        0      0            0             0                 0   \n",
      "26212        0        0      0            0             0                 0   \n",
      "26213        1        0      0            0             0                 0   \n",
      "26214        1        0      0            1             0                 0   \n",
      "26215        1        0      0            0             0                 0   \n",
      "\n",
      "       search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
      "0                      0         0         0            0  ...            0   \n",
      "1                      0         0         0            0  ...            0   \n",
      "2                      0         0         0            0  ...            0   \n",
      "3                      0         0         0            0  ...            0   \n",
      "4                      0         0         0            0  ...            0   \n",
      "...                  ...       ...       ...          ...  ...          ...   \n",
      "26211                  0         0         0            0  ...            0   \n",
      "26212                  0         0         0            0  ...            0   \n",
      "26213                  0         0         0            0  ...            0   \n",
      "26214                  0         0         1            0  ...            0   \n",
      "26215                  0         0         0            0  ...            0   \n",
      "\n",
      "       other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
      "0                         0                0       0      0     0           0   \n",
      "1                         0                1       0      1     0           0   \n",
      "2                         0                0       0      0     0           0   \n",
      "3                         0                0       0      0     0           0   \n",
      "4                         0                0       0      0     0           0   \n",
      "...                     ...              ...     ...    ...   ...         ...   \n",
      "26211                     0                0       0      0     0           0   \n",
      "26212                     0                0       0      0     0           0   \n",
      "26213                     0                0       0      0     0           0   \n",
      "26214                     0                0       0      0     0           0   \n",
      "26215                     0                0       0      0     0           0   \n",
      "\n",
      "       cold  other_weather  direct_report  \n",
      "0         0              0              0  \n",
      "1         0              0              0  \n",
      "2         0              0              0  \n",
      "3         0              0              0  \n",
      "4         0              0              0  \n",
      "...     ...            ...            ...  \n",
      "26211     0              0              0  \n",
      "26212     0              0              0  \n",
      "26213     0              0              0  \n",
      "26214     0              0              0  \n",
      "26215     0              0              0  \n",
      "\n",
      "[26216 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Defining feature and target dataframes\n",
    "X,Y = df['message'], df.iloc[:,4:]\n",
    "\n",
    "# Target labels\n",
    "category_names = Y.columns\n",
    "\n",
    "# Mapping any values except 0/1 for each column with randomly selected 0/1\n",
    "for column in category_names:\n",
    "    Y[column] = Y[column].map(lambda x: randrange(0,2) if x > 1 or x < 0 else x)\n",
    "\n",
    "print(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Write a tokenization function to process your text data\"\"\"\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    # Convert text to lowercase and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # Tokenize words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # remove stop words\n",
    "    stopwords_ = stopwords.words(\"english\")\n",
    "    words = [word for word in words if word not in stopwords_]\n",
    "    \n",
    "    # extract root form of words\n",
    "    words = [WordNetLemmatizer().lemmatize(word, pos='v') for word in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(pipeline, X_train, X_test, Y_train):\n",
    "    pipeline.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predictions on test for the pipeline provided\n",
    "    Y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(Y_pred, Y_test):\n",
    "    Y_pred = pd.DataFrame(Y_pred, columns=[Y_test.columns])\n",
    "\n",
    "    print(classification_report(Y_test.values, y_pred, target_names=category_names))\n",
    "    \n",
    "    # print accuracy score\n",
    "    print('Accuracy: {}'.format(np.mean(Y_test.values == y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultiOutputClassifier(RandomForestClassifier())),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and predict y_pred on pipeline\n",
    "y_pred = fit_and_predict(pipeline, X_train, X_test, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9482080493676466\n"
     ]
    }
   ],
   "source": [
    "test_model(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved model\n",
    "pipeline_improved = Pipeline([('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultiOutputClassifier(OneVsRestClassifier(LinearSVC())))\n",
    "                    ])\n",
    "\n",
    "\n",
    "# parameters added\n",
    "parameters = {'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "              'vect__max_df': (0.75, 1.0),\n",
    "            }\n",
    "\n",
    "# create model\n",
    "model = GridSearchCV(estimator=pipeline, param_grid=parameters, verbose=3, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] vect__max_df=0.75, vect__ngram_range=(1, 1) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=0.75, vect__ngram_range=(1, 1), score=0.263, total= 7.8min\n",
      "[CV] vect__max_df=0.75, vect__ngram_range=(1, 1) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=0.75, vect__ngram_range=(1, 1), score=0.264, total= 7.8min\n",
      "[CV] vect__max_df=0.75, vect__ngram_range=(1, 1) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 15.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=0.75, vect__ngram_range=(1, 1), score=0.258, total= 7.8min\n",
      "[CV] vect__max_df=0.75, vect__ngram_range=(1, 2) .....................\n",
      "[CV]  vect__max_df=0.75, vect__ngram_range=(1, 2), score=0.267, total=19.4min\n",
      "[CV] vect__max_df=0.75, vect__ngram_range=(1, 2) .....................\n",
      "[CV]  vect__max_df=0.75, vect__ngram_range=(1, 2), score=0.262, total=20.9min\n",
      "[CV] vect__max_df=0.75, vect__ngram_range=(1, 2) .....................\n",
      "[CV]  vect__max_df=0.75, vect__ngram_range=(1, 2), score=0.262, total=21.1min\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 1) ......................\n",
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.265, total= 3.8min\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 1) ......................\n",
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.266, total= 4.1min\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 1) ......................\n",
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.258, total= 4.1min\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 2) ......................\n",
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.271, total=10.3min\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 2) ......................\n",
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.264, total=10.3min\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 2) ......................\n",
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.264, total=10.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 128.1min finished\n"
     ]
    }
   ],
   "source": [
    "y_pred_improved = fit_and_predict(model, X_train, X_test, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.95      0.89      4991\n",
      "               request       0.85      0.51      0.63      1045\n",
      "                 offer       0.00      0.00      0.00        28\n",
      "           aid_related       0.75      0.69      0.72      2660\n",
      "          medical_help       0.74      0.08      0.14       535\n",
      "      medical_products       0.81      0.08      0.14       328\n",
      "     search_and_rescue       0.89      0.05      0.09       167\n",
      "              security       1.00      0.02      0.03       125\n",
      "              military       0.50      0.05      0.09       211\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.90      0.41      0.56       425\n",
      "                  food       0.83      0.54      0.66       705\n",
      "               shelter       0.83      0.34      0.48       563\n",
      "              clothing       0.67      0.08      0.14       103\n",
      "                 money       0.88      0.05      0.10       138\n",
      "        missing_people       1.00      0.01      0.03        67\n",
      "              refugees       0.38      0.01      0.03       230\n",
      "                 death       0.83      0.12      0.21       290\n",
      "             other_aid       0.40      0.03      0.05       826\n",
      "infrastructure_related       0.00      0.00      0.00       440\n",
      "             transport       0.81      0.08      0.15       306\n",
      "             buildings       0.75      0.11      0.20       336\n",
      "           electricity       0.00      0.00      0.00       126\n",
      "                 tools       0.00      0.00      0.00        38\n",
      "             hospitals       0.00      0.00      0.00        73\n",
      "                 shops       0.00      0.00      0.00        37\n",
      "           aid_centers       0.00      0.00      0.00        74\n",
      "  other_infrastructure       0.00      0.00      0.00       301\n",
      "       weather_related       0.85      0.70      0.76      1891\n",
      "                floods       0.92      0.48      0.63       597\n",
      "                 storm       0.77      0.54      0.64       659\n",
      "                  fire       1.00      0.01      0.03        70\n",
      "            earthquake       0.87      0.80      0.83       585\n",
      "                  cold       0.80      0.05      0.09       159\n",
      "         other_weather       0.50      0.04      0.07       360\n",
      "         direct_report       0.80      0.36      0.49      1252\n",
      "\n",
      "             micro avg       0.82      0.53      0.64     20741\n",
      "             macro avg       0.59      0.20      0.25     20741\n",
      "          weighted avg       0.75      0.53      0.57     20741\n",
      "           samples avg       0.66      0.48      0.51     20741\n",
      "\n",
      "Accuracy: 0.9482080493676466\n"
     ]
    }
   ],
   "source": [
    "test_model(y_pred_improved, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_filepath):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function saves the model to a Python pickle file\n",
    "\n",
    "    Args:\n",
    "    model: Trained model\n",
    "    model_filepath: Location to save the model\n",
    "\n",
    "    Returns:\n",
    "    none - Saves the model to pickle file\n",
    "    \"\"\"\n",
    "\n",
    "    # save model to pickle file\n",
    "    pickle.dump(model, open(model_filepath, 'wb'))\n",
    "    \n",
    "    print('Trained model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved!\n"
     ]
    }
   ],
   "source": [
    "save_model(model, 'classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
